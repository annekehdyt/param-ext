{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "def load_data(path):\n",
    "    io_files = glob.glob(path+\"/io/*.txt\")\n",
    "    nio_files = glob.glob(path+\"/nonio/*.txt\")\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    for iof in io_files:\n",
    "            f = open(iof, 'r', encoding=\"utf8\")\n",
    "            line = f.read()\n",
    "            #line = line[:len(line)/2]\n",
    "            X.append(line)\n",
    "            y.append(1)\n",
    "            f.close()\n",
    "\n",
    "    for niof in nio_files:\n",
    "            f = open(niof, 'r', encoding=\"utf8\")\n",
    "            line = f.read()\n",
    "            #line = line[:len(line)/2]\n",
    "            X.append(line)\n",
    "            y.append(0)\n",
    "            f.close()\n",
    "\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def generate_token_sequence(X_corpus, word_dict, token):\n",
    "    import re\n",
    "\n",
    "    token_pattern = re.compile(token)\n",
    "    X = []\n",
    "    i=0\n",
    "    for sentence in X_corpus:\n",
    "        split = token_pattern.findall(sentence)\n",
    "        seq = []\n",
    "        for word in split:\n",
    "            try:\n",
    "                seq.append(word_dict[word])\n",
    "            except KeyError:\n",
    "                continue\n",
    "        X.append(seq)\n",
    "\n",
    "    return np.asarray(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data(\"./dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 0\n",
      "main()\n",
      "{\n",
      "    void* buff = calloc(1024, 1);\n",
      "    FILE* fh = fopen(\"filename.txt\", \"rt\");\n",
      "    fwrite(buff, 1024,1, fh);\n",
      "    fclose(fh);\n",
      "}\n",
      "File 1\n",
      "main() \n",
      "{\n",
      "   FILE *fp;\n",
      "   char buff[255];\n",
      "\n",
      "   fp = fopen(\"/tmp/test.txt\", \"r\");\n",
      "   fscanf(fp, \"%s\", buff);\n",
      "   printf(\"1 : %s\\n\", buff );\n",
      "\n",
      "   fgets(buff, 255, (FILE*)fp);\n",
      "   printf(\"2: %s\\n\", buff );\n",
      "   \n",
      "   fgets(buff, 255, (FILE*)fp);\n",
      "   printf(\"3: %s\\n\", buff );\n",
      "   fclose(fp);\n",
      "}\n",
      "File 2\n",
      "int main( )               \n",
      "{\n",
      "    float m, n ;\n",
      "    printf ( \"\\nEnter some number for finding square \\n\");\n",
      "    scanf ( \"%f\", &m ) ;\n",
      "    n = square ( m ) ;                      \n",
      "    printf ( \"\\nSquare of the given number %f is %f\",m,n );\n",
      "}\n",
      "File 3\n",
      "int main(int argc, char* argv[] )\n",
      "{\n",
      "    printf( \"argc = %d\\n\", argc );\n",
      "    for( int i = 0; i < argc; ++i ) {\n",
      "        printf( \"argv[ %d ] = %s\\n\", i, argv[ i ] );\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for i,x in enumerate(X):\n",
    "    print('File',i)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t0.161364\n",
      "1024\t0.137276\n",
      "2\t0.024088\n",
      "255\t0.072265\n",
      "3\t0.024088\n",
      "buff\t0.305895\n",
      "calloc\t0.068638\n",
      "fclose\t0.092726\n",
      "fgets\t0.048177\n",
      "fh\t0.205914\n",
      "file\t0.140903\n",
      "filename\t0.068638\n",
      "fopen\t0.092726\n",
      "fp\t0.144530\n",
      "fscanf\t0.024088\n",
      "fwrite\t0.068638\n",
      "main\t0.009238\n",
      "r\t0.024088\n",
      "rt\t0.068638\n",
      "s\t0.057402\n",
      "tmp/test\t0.024088\n",
      "txt\t0.092726\n",
      "void\t0.068638\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "token = r\"(?u)\\b[\\w\\'/]+\\b\"\n",
    "cv = CountVectorizer(lowercase=True, max_df=1.0, min_df=1, binary=False, token_pattern=token, ngram_range=(1,1))\n",
    "cv.fit(X)\n",
    "X_tr = cv.transform(X)\n",
    "X_tr.shape\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_tr, y)\n",
    "#print(clf.score(X_tr,y))\n",
    "\n",
    "word = cv.get_feature_names()\n",
    "coef = clf.coef_.flatten()\n",
    "\n",
    "for i,word in enumerate(word):\n",
    "    if coef[i] > 0:\n",
    "        print(\"%s\\t%f\" %(word, coef[i]))\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words : 47\n",
      "Generate token sequence...\n",
      "Generate pad sequences...\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (4, 100)\n",
      "Generate one hot...\n"
     ]
    }
   ],
   "source": [
    "# LSTM\n",
    "cv.fit(X)\n",
    "word_dict = cv.vocabulary_\n",
    "dict_len = len(cv.get_feature_names())\n",
    "word_feature = cv.get_feature_names()\n",
    "  \n",
    "print('Words :', len(cv.get_feature_names()))\n",
    "  \n",
    "print('Generate token sequence...')\n",
    "X_train = generate_token_sequence(X, word_dict, token)\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "print('Generate pad sequences...')\n",
    "print('Pad sequences (samples x time)')\n",
    "maxlen=100\n",
    "x_train = pad_sequences(X_train, maxlen=maxlen, padding='pre', truncating='pre', value=0)\n",
    "print('x_train shape:', x_train.shape)\n",
    "\n",
    "del X_train\n",
    "\n",
    "print('Generate one hot...')\n",
    "\n",
    "def generate_one_hot(X):\n",
    "    X_one_hot = []\n",
    "  \n",
    "    for sent in X:\n",
    "        sent_reverse = []\n",
    "        for idx in sent:\n",
    "            sent_reverse.append(word_feature[idx])\n",
    "        sent_transform = tf_vectorizer.transform(sent_reverse).todense()\n",
    "        X_one_hot.append(sent_transform)\n",
    "        del sent_transform\n",
    "    return np.array(X_one_hot)\n",
    "\n",
    "X_train_hot = generate_one_hot(x_train)\n",
    "del x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 100, 47)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anneke Hidayat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\Anneke Hidayat\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(input_shape=(None, 47), units=100)`\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 100)               59200     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 59,301\n",
      "Trainable params: 59,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train...\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential  \n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "\n",
    "hidden_neurons = 100\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "# model.add(Embedding(dict_len, 100))\n",
    "model.add(LSTM(output_dim=hidden_neurons, input_dim=dict_len))\n",
    "model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])  \n",
    "print(model.summary())\n",
    "\n",
    "print('Train...')\n",
    "hist = model.fit(X_train_hot, y, epochs=100, verbose=0, shuffle=False)\n",
    "\n",
    "y_pred = model.predict(X_train_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99857235],\n",
       "       [0.9985917 ],\n",
       "       [0.00106561],\n",
       "       [0.00106516]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
